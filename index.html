

<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Artificial intelligence and Morality
Winter semester 2022 – 2023
</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta name="author" content="Yehuda Baharav" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="" />
<meta property="og:description" content="" />
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta property='og:title' content=''/>
    <meta property='og:description' content=''/>
    
    <link rel="stylesheet" href="stylesheet.css">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Breaking the Bias: How to Recognize and Avoid Gender Bias in Recruiting Ads</h1>
      <h2 class="curse-name">Artificial intelligence and Morality
      </h2>
      <h2 class="semester-name">Winter semester 2022 – 2023</h2>
      <h2 class="reichman-name">Reichman University</h2>
      <!-- <h2 class="project-tagline" color=white><a href="website_homepage.htm">Home</a> <a href="website_hills.htm">Hills Pupil Tailored Website</a></h2> -->
      <h2 class="project-tagline"><a href="https://www.linkedin.com/in/yehuda-baharav/"  style="color:#ffffff">Yehuda Baharav - Efi Arazi School of Computer Science</a>
      <h2 class="project-tagline"><a href="https://www.linkedin.com/in/tomer-bar-tal-516127241"  style="color:#ffffff">Tomer Bar-Tal - Radzyner Law School</a>
      <h2 class="project-tagline"><a style="color:#ffffff">Shahaf Sherman - Radzyner Law School</a>
      <h2 class="project-tagline"><a style="color:#ffffff">Nizar - Radzyner Law School</a>     
    </header>

    <main id="content" class="main-content" role="main">

This paper was written by 
      <a href="https://www.linkedin.com/in/yehuda-baharav/">Yehuda Baharav</a>, <a href="https://www.linkedin.com/in/tomer-bar-tal-516127241">Tomer Bar-Tal</a>, Shahaf Sherman and Nizar from Reichman University.

<h2 id="Introduction">Introduction</h2>

<p>
Gender bias in job ads is a prevalent issue that has been extensively studied, particularly with regard to its impact on women  . Research has shown that women are more likely to apply for job postings only when they match the requirements almost perfectly, while men are more willing to apply even if they only partially meet the qualifications  
</p>
<p>
Bias in recruitment ads can take different forms, including the use of gender-specific terms like Policeman or Fireman, or the use of language that is more appealing to one gender over the other . There is also a more subtle type of bias in the wording or phrasing of ads, which may not be intentionally offensive but can still be alienating to one gender, typically women. Examples of such wording include the use of phrases like "must have" or "commitment". 
</p>
<p>
To address this problem, we will build a website that will assist recruiters in writing gender-neutral job ads. The goal of the website is to help recruiters recognize and eliminate any gender bias in their job ads, thus increasing diversity and inclusivity in the workplace. 
</p>

<h2 id="methodology">Methodology</h2>
<p>
  In the initial phase of our research, we opted to construct an NLP (Natural Language Processing) model aimed at identifying instances of gender bias in recruitment advertisements.
 </p>
<strong>Data:</strong>      
<p>We obtained the data from <a href="https://pandologic.com/">Pandologic</a>, which consists of 2 tables:</p>
 <p>     
<li>
<strong>Jobs table</strong>, containing the job title, field, and description.
Its size is about <strong>50K samples</strong>.
</li>
<li>
<strong>Job seekers table</strong> that includes their first and last names, email addresses, physical addresses, and other personal information. This table also indicates the jobs for which each job seeker applied.
Its size is about <strong>15M samples</strong>.
</li>
 </p>
  
<ol>
   <center><p><img width="500" src="images/image001.png" /></p></center>
</ol>
<ol>
<center><p><img width="500" src="images/image002.png" /></p></center>
</ol>
<p>To ensure <strong>information security</strong> and protect <strong>user privacy</strong>, I have not included all columns in the presentation of data. Additionally, (just for the presentation here) the columns have been deliberately mixed up and a fictitious CompPositionID has been used.</p>

<strong>Date engineering:</strong>
      
<p>We used the <a href="https://pypi.org/project/gender-guesser/">gender_guesser</a> library to extract the gender of users from the list of unique first names in the data. Afterward, we joined this information back to the users table.
  For example:</p>
<center><p><img width="500" src="images/image003.png" /></p></center>
      
 <strong>Bias index:</strong>    
 <p>
   To assess gender bias in job applications, we calculated a gender ratio by comparing the number of women who applied for each job to the number of men who applied for that same job. We then computed this ratio for each job field, such as lawyer or doctor, in our dataset.
</p>
<p> 
  Next, we developed a "bias index" that measures the variance or distance between the job ratio for each specific job and the average ratio for that job field. This index provides information about whether there is gender bias in the applicant pool for a particular job, relative to the overall ratio for that job field. The index ranges from -1 to 1, with -1 indicating bias against women, 1 indicating bias against men, and 0 indicating no bias.
</p>
<p> 
 To increase confidence in our analysis, we excluded job fields with fewer than 10 unique ads and jobs with fewer than 5 applicants.  
</p>

 <strong>Example:</strong> 
<p>
  Upon examining the jobs with the highest gender bias according to the index, we discovered several positions that exhibited a significant disparity in applications between men and women. For example, the attached  job of a Medical Office Manager demonstrated a gender gap,  with 51 applicants, all of them are male, while in average in this job field, 87% of the applicants are females.
</p>
<hr>    
      
      
      
      
<h2 id="stochastic-gradient-descent">Stochastic Gradient Descent</h2>

<p>Before we dive into the implementation details and challenges, let’s first understand what stochastic gradient
    descent (SGD) is. Given a dataset D and a model with θ parameters, we’d like to minimize the parameterized empirical
    loss function, L, for a given (x,y) pairs in D, where x denotes the input sample while y is the output.</p>
<ol>
   <center><p><img width="500" src="images/loss_function.png" /></p></center>
</ol>
      
<p>Where l is the loss of a data point (x,y) for model θ. </p>
<p>A first-order stochastic optimization algorithm optimizes the loss function by iteratively updating θ using a
    stochastic gradient. Usually, a learning rate will be applied to avoid over or underfitting, and therefore,
    the SGD will be calculated as follows:</p>
<ol>
   <center><center><p><img width="500" src="images/SGD.png" /></p></center>
</ol>     
<p>where ɣ is the learning rate or step size at iteration.</p>
<p>A mini-batch version of the stochastic optimization algorithm computes the gradient over a mini-batch of size B
    instead of a single data point:</p>
<ol>
   <center><p><img width="500" src="images/mini_batch_size_b.png" /></p></center>
</ol>      
<h2 id="synchronous-stochastic-gradient-descent">Synchronous stochastic gradient descent</h2>
<p>Using distributed Synchronous Stochastic Gradient Descent (Sync-SGD), a root aggregator node splits the data into
    batches and fans-out requests to leaf nodes (worker machines) to process each batch and compute its gradient
    independently. Once all machines return their result, the root aggregator node averages the gradient and sends
    it back to the workers to update the model’s parameters. The root aggregator iterates over this process for a given
    number of epochs or based on a conversion condition.</p>
<ol>
  <center><div class="img-Sync-SGD-diagram">
    <img width="500" img src="images/Sync-SGD-diagram.png" alt="FIGURE 1: DISTRIBUTED SYNCHRONOUS STOCHASTIC GRADIENT DESCENT FLOW" />
    <p>FIGURE 1: DISTRIBUTED SYNCHRONOUS STOCHASTIC GRADIENT DESCENT FLOW</p>
</div></center>
</ol> 
<h2 id="Issues">Issues</h2> 
<p>In theory, distributing the computation onto T worker machines should give a performance improvement of xT. Yet, in
    reality, the performance improvement is rarely xT. The decline in efficiency is caused due to many reasons, where
    recent researches segment Stragglers= as the main root cause.</p>
 
      
<p>
Stragglers are tasks that run much slower than other workers. Slow stragglers may result from failing hardware,
    contention on shared underlying hardware resources in data centers, or even preemption by other jobs.
  <a href="https://arxiv.org/abs/1604.00981">Rafal et al. (2017)</a>
  conducted an experiment that calculated the time it takes to run a Sync-SGD using 100 workers and 19 parameters on
    the Inception model. These times are presented in Figure 2.
</p>
<ol>
<center><div class="img-cdf-time">
    <img width="500" img src="images/cdf_time.png" alt="cdf_time" />
    <p>FIGURE 2: THE EFFECT OF NUMBER OF WORKERS ON THE SYNC-SGD TRAINING TIME, by
       <a href="https://arxiv.org/abs/1604.00981"> Rafal et al. (2017)</a>
    </p>
</div></center>
</ol>     
      
 

     
<h2 id="solutions">Solutions</h2>

<p>
  The “arming race” for state-of-the-art machine learning models has led the industry to develop complex systems that require heavy computing to train.
  When it comes to such a large scale, any delay in the training cycle sum to a significant delay in the entire training process.
  To meet those high requirements and reduce the iteration time, researchers from academia and industry invest considerable time and
  resources in refining and streamlining the training process. we’ve gathered SOTA solutions for stragglers that
  improves the training time when using the Sync-SGD approach.
</p>     

<h3 id="drop-stragglers">drop-stragglers</h3> 
<p>
  Our initial approach to solving this issue was to drop the results of the stragglers and calculate the gradient using
    the results from the other workers. I supported this approach using two main hypotheses:
</p>
      
<ul class="ul-2">
  <li>Low ratio of stragglers to completed tasks — As fanning out to more workers, the number of stragglers increases,
      however, they only accommodate the ~98th percentile, and therefore their impact will be relatively small on the gradient on average.</li>
  <li>Reducing a small amount of data from a large-scale dataset has little effect — The Sync-SGD method is used for a
      large amount of data. Thus, removing the result of the small batches from the training process will have a negligible effect on the gradient on average.</li>
</ul> 
<p>
  However, our intonation was proven wrong by Rafal et al. (2017). They examined the effect of dropping the results of
    stragglers without using backup workers. Having fewer machines implies a smaller effective mini-batch size and thus
    greater gradient variance, which requires more iterations for convergence.
</p>  
  
<center><div class="img-iterations">
    <img width="500" img src="images/iterations.png" alt="iterations" />
    <p>FIGURE 5: NUMBER OF ITERATIONS TO CONVERGE, by 
       <a href="https://arxiv.org/abs/1604.00981">Rafal et al. (2017)</a>
    </p>
</div></center>

<p>
 As shown in figure 5, the iterations needed to converge increase when reducing the number of workers we aggregate the gradient from. Thus,
  our approach reduces the iteration time per batch but increases the number of epochs to conversion and, therefore, the total training time.
 </p> 
<h3 id="backup-workers">Backup Workers</h3>
<p>
  Rafal et al. (2017) approached the straggler drawback using technics from other distributed systems
  (<a href="https://www.ibm.com/topics/mapreduce#:~:text=MapReduce%20is%20a%20programming%20paradigm,tasks%20that%20Hadoop%20programs%20perform.">MapReduce</a>,
  <a href="https://www.microsoft.com/en-us/research/project/dryad/">Dryad</a>,
  <a href="https://hadoop.apache.org/">Hadoop</a>,
  and <a href="https://spark.apache.org/">Spark</a>).
  They choose to add b backup workers to the N workers. Once the root aggregator receives N inputs,
  it aggregates their gradient and updates the parameters. The slowest b workers’ gradients are dropped when they arrive.
  From figure 2, we can see that their experiment resulted in 80% of the 98th gradient arriving under 2s,
  whereas only 30% of the final gradient did. Furthermore, the time to collect the final few gradients grows exponentially,
  resulting in wasted idle resources and time expended to wait for the slowest gradients.
</p>
      
<p>
  As part of the research, they ran empirical comparisons of synchronous and 
  <a href="https://arxiv.org/abs/1609.08326">Asynchronous distributed stochastic gradient descent</a>  
  algorithms on the
  <a href="https://cloud.google.com/tpu/docs/inception-v3-advanced">Inception model</a>  
  (Szegedy et al., 2016) trained on 
  <a href="https://www.image-net.org/">ImageNet Challenge dataset</a>
  
  (Russakovsky et al., 2015).
</p>
      
 <center><div class="img-convergence">
    <img width="500" img src="images/convergence_plots.png" alt="convergence" />
    <p>FIGURE 6: CONVERGENCE OF SYNC-SGD AND ASYNC-SGD ON INCEPTION MODEL USING VARYING NUMBER OF MACHINES, by
       <a href="https://arxiv.org/abs/1604.00981">Rafal et al. (2017)</a>
    </p>
</div></center>
 
<p>
  From figure 6, we can see how using different numbers of workers and backup workers (N+b) has a clear effect on
    conversion time and rate. Figure 6 (b), shows that fanning out more workers doesn’t necessarily provide better
    results. When passing ~105 workers, the model’s precision decreases by ~0.3%. Moreover, In figure 6 (c) and 6 (d),
    the improvement slope decrease as the number of workers increases, which is reflected in the “elbow” shape.
</p>    

<h2 id="Conclusion">Conclusion</h2>
<p>
  As the size of datasets and models’ complexity increases, distributed training will become more and more common in
    the MLOps ecosystem. As we saw, a delay in one training cycle has a high impact on the entire training process.
    Thus, the need to perfect the training process and reduce the time per epoch is high. If you have more ideas,
    questions, or thoughts — I’d love to hear about them!
      </p>
      
      
      
      
      
    </main>
  </body>
</html>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML"></script>
